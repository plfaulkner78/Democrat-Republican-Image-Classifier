{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the images you need from the US Congress website and store them locally in a directory us_congress_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of dicts containing the image url and the party of each member of Congress\n",
    "urls_and_labels = []\n",
    "base_url = 'https://www.congress.gov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape all the image urls and party affiliations\n",
    "\n",
    "def get_congress_urls(url_string):\n",
    "    \"\"\"\n",
    "    Function takes as input a url from the US Congress website.\n",
    "    The website displays members of Congress along with their photo\n",
    "    and party affiliation. The function then extracts the url of the photo \n",
    "    (so the photo can be downloaded from that url later) and the party of each \n",
    "    member, stores them in a dict, and appends the dict to the urls_and_labels list.\n",
    "    \"\"\"\n",
    "    page = requests.get(url_string)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    congressmen = soup.find_all('li', class_=\"expanded\")\n",
    "    \n",
    "    for person in congressmen:\n",
    "        img_elm = person.find('div', class_='member-image')\n",
    "        if img_elm == None: # if there's no picture, then don't add the congressmember to the dataset\n",
    "            continue\n",
    "        img_src = img_elm.find('img')['src']\n",
    "        info_elements = person.find('div', class_=\"member-profile\").find_all('span')\n",
    "        for elm in info_elements:\n",
    "            if \"Party\" in elm.text:\n",
    "                party_text = elm.find('span').text\n",
    "                if party_text == \"Democratic\": # Democrats will be coded as 0, Republicans as 1\n",
    "                    party = 0                # (includes Libertarian Amash as a Republican because he used to be one)\n",
    "                else:\n",
    "                    party = 1\n",
    "                \n",
    "        urls_and_labels.append({ \"url\": base_url + img_src, \"party\": party })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Run the above function on all three urls that list members of Congress*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1 = 'https://www.congress.gov/members?q={%22congress%22:%22116%22}&pageSize=250&page=1&searchResultViewType=expanded'\n",
    "url_2 = 'https://www.congress.gov/members?q=%7B%22congress%22%3A%22116%22%7D&searchResultViewType=expanded&pageSize=250&page=2'\n",
    "url_3 = 'https://www.congress.gov/members?q=%7B%22congress%22%3A%22116%22%7D&searchResultViewType=expanded&pageSize=250&page=3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in [url_1, url_2, url_3]:\n",
    "    get_congress_urls(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls_and_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list has 537 elements which is odd because there are only 535 members of Congress (435 in the House and 100 Senators). After investigating further, it turns out that in addition to these 535 memebers, there are 6 non-voting memebers of the House from US Territories. This should put the total at 541, but 4 memebers of Congress did not have photos, which explains the final 537 number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Next, download each image and save it locally*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Function below downloads each image and save it locally. \n",
    "# It also keeps track of how long the download took in seconds.\n",
    "def download_congress_images(url_list):\n",
    "    \"\"\"\n",
    "    Takes of list of image urls and downloads each image.\n",
    "    Then it saves each image locally, while strategically\n",
    "    naming each image according to its political party.\n",
    "    Later I will exploit the fact that the party is included in\n",
    "    the file name when I create my labeled dataset.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    for member_obj in url_list:\n",
    "        url = member_obj['url']\n",
    "        data = requests.get(url).content\n",
    "        if member_obj['party'] == 0:\n",
    "            party = 'democrat'\n",
    "        else:\n",
    "            party = 'republican'\n",
    "        with open(\"us_congress_images/\" + party + '_' + url[36:], 'wb+') as f:\n",
    "            f.write(data)\n",
    "    f.close()\n",
    "    end = time.time()\n",
    "    print(end - start, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132.96079802513123  seconds\n"
     ]
    }
   ],
   "source": [
    "download_congress_images(urls_and_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now all the images have been downloaded and you can start building dataset and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
